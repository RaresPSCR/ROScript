/**
 * @file parser.cpp
 * @brief Parser implementation for the Roscript interpreter.
 *
 * This file contains the implementation of the parser for the Roscript interpreter. It includes functions to parse expressions, variable declarations, and error handling.
 * It's header contains the definitions of the AST nodes and the parser functions.
 * @see parser.h
 * 
 * IMPORTANT
 * This is the description of the parse_rhs_expression function, which is the core of the parser. It handles operator precedence and associativity, and recursively parses right-hand side expressions.
 * @image html prhse.png
 *
 * @author Rares-Cosma & Vlad-Oprea
 * @date 2025-04-25
 */
#include "parser.h"
#include "commons.cpp"

struct Token {
	int line_nb;
	string line;
	string value;
	string type;
};

/**
 * @class TokenStream
 * @brief A class to handle the tokens generated by the lexer.
 * @note This class stores the raw tokens and the number of tokens per line, and reconstructs lines for error reporting.
 */

class TokenStream {
public:
    vector<pair<string, string>> raw_tokens; // {type, value} 
    vector<Token> tokens; // final token list

    void init(vector<int> tokens_per_line) {
        /**
         * @brief Initializes the TokenStream by using tokens_per_line to build each token's line context and number.
         * @note This function assumes that tokens_per_line aligns exactly with the number of logical lines in the source code.
         */
        size_t token_index = 0;
        int line_number = 1;

        for (int count : tokens_per_line) {
            vector<string> current_line_texts;
            string full_line;

            for (int i = 0; i < count; ++i) {
                if (token_index >= raw_tokens.size()) break;

                auto [type, value] = raw_tokens[token_index++];
                current_line_texts.push_back(value);
            }

            full_line = join(current_line_texts, " ");

            for (int i = 0; i < count; ++i) {
                const auto& [type, value] = raw_tokens[token_index - count + i];
                tokens.push_back({line_number, full_line, value, type});
            }

            line_number++;
        }
    }

private:
    std::string join(const std::vector<std::string>& words, const std::string& sep) {
        std::string result;
        for (size_t i = 0; i < words.size(); ++i) {
            result += words[i];
            if (i + 1 < words.size()) result += sep;
        }
        return result;
    }
};


// ABSTRACT SYNTAX TREE IMPLEMEMTATION

vector<ASTNode*> AST; // vector of AST nodes
vector<string> parser_variables; // vector of variables
vector<string> parser_user_defined_fn; // vector of user defined functions

// PARSER IMPLEMENTATION

int get_precedence(const string& op) {
	if (op == "+" || op == "-") return 1;
	if (op == "*" || op == "/" || op == "%") return 2;
	return 0;
}

Expr* parse_expression(const vector<Token>& tokens, int& idx);

Expr* parse_primary_expression(const vector<Token>& tokens, int& idx) {

	/**
 	* @brief Parses the simplest elements of an expression (literals and variable references).
 	* @param tokens The tokens to parse.
 	* @param idx The current index in the tokens vector.
 	* @return The coresponding derived expression.
	 */

    if (idx >= tokens.size()) return nullptr;

    if (tokens[idx].type == "INT") {
        int value = stoi(tokens[idx].value);
        idx++;
        return new IntLiteral(value);
    }
    else if (tokens[idx].type == "FLOAT") {
        float value = stof(tokens[idx].value);
        idx++;
        return new FloatLiteral(value);
    }
    else if (tokens[idx].type == "STRING") {
        string value = tokens[idx].value;
        idx++;
        return new StringLiteral(value);
    }
    else if (tokens[idx].type == "ID") {
        string name = tokens[idx].value;
        idx++;
        if (idx < tokens.size() && tokens[idx].type == "LPAREN") {
        	if (stdlib.find(name) != stdlib.end()) {
            	idx++;
            	vector<Expr*> args;

        		while (idx < tokens.size() && tokens[idx].type != "RPAREN") {
                	args.push_back(parse_expression(tokens,idx));
                	if (tokens[idx].type == "COMMA") idx++; // consume ',' between args
            	}

            	if (idx >= tokens.size() || tokens[idx].type != "RPAREN") {
                	throw std::runtime_error("Expected ')' after function arguments");
            	}
            	idx++;

            	return new FunctionCall(name, args);
        	} else {
            	throw std::runtime_error("Unknown function: " + name);
        	}
    	}

    	return new Refrence(name);
    }
	else if (tokens[idx].type == "LPAREN") {
        idx++; // consume (
        Expr* expr = parse_expression(tokens, idx);
        if (idx >= tokens.size() || tokens[idx].type != "RPAREN") {
            cerr << "Error: expected ')' after expression" << endl;
            return nullptr;
        }
        idx++; // consume )
        return expr;
    }
    return nullptr;
}

Expr* parse_rhs_expression(int expr_prec, Expr* lhs, const vector<Token>& tokens, int& idx) {
	/**
 	* @brief Parses right-hand expression.
 	* @param expr_prec The current expression precedence.
	* @param lhs The left-hand side expression.
	* @param tokens The tokens to parse.
 	* @param idx The current index in the tokens vector.
	* @note This function is the core to our parser, because it handles the precedence of the operators and the associativity. It is recursive and will call itself to parse the right-hand side expression.
 	* @return BinaryExpr combining the left and right expressions.
	 */

	while (idx < tokens.size()) {
        if (tokens[idx].type != "OP") return lhs;
        string op = tokens[idx].value;
        int prec = get_precedence(op);

        if (prec < expr_prec) break;

        idx++; // consume operator
        Expr* rhs = parse_primary_expression(tokens, idx);
        if (!rhs) return nullptr;

        while (idx < tokens.size() && tokens[idx].type == "OP" &&
               get_precedence(tokens[idx].value) >= prec) {
            rhs = parse_rhs_expression(get_precedence(tokens[idx].value), rhs, tokens, idx);
        }

        lhs = new BinaryExpr(lhs, op, rhs);
    }

    return lhs;
}

Expr* parse_expression(const vector<Token>& tokens, int& idx) {
	/**
 	* @brief Parses an expression and returns the corresponding AST node.
 	* @param tokens The tokens to parse.
 	* @param idx The current index in the tokens vector.
 	* @return The parsed expression as an AST node.
	 */
	if (idx >= tokens.size()) return nullptr;
	Expr* left = parse_primary_expression(tokens, idx);
	if (!left) return nullptr;

	return parse_rhs_expression(0, left, tokens, idx);
}

vector<ASTNode*> parse_block(vector<Token> tokens, int& idx);

void report_error(const string& msg, const string& line, int line_nb) {
	/**
 	* @brief Thows custom syntax errors.
 	* @param line The line of the error.
 	* @param line_nb The line number in the source code.
 	* @return Prints the error message and the line of code.
	 */
	cerr << "Syntax Error: " << msg << "\nOn line: ";
	cout << line_nb << ": ";
	cout << line;
	cerr << "\n\n";
}

void parse_variable_declaration(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a variable declaration line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the variable declaration to the AST.
 	* @note Because "var" is not a type spefcific keyword, we cannot determine the type of the variable, in case it has no initializer so we add it to the NDT stack (non determined) and relocate it later.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++;

	if (tokens[idx].type != "ID") {
		report_error("Expected variable name after 'var'", start_line, start_line_nb);
		return;
	}

	string name=tokens[idx].value;
	idx++;

	if (idx<tokens.size() && (tokens[idx].type=="NLINE"||tokens[idx].type=="COMMA"||tokens[idx].value==";"||tokens[idx].value==")")) {
		Expr* default_value = new IntLiteral(0);
        ASTNode* node = new VariableDeclaration("NDT", name, default_value);
		parser_variables.push_back(name); // add variable to the list of variables
        AST.push_back(node);
		idx++;
	} else if (idx<tokens.size()) {
		idx++;
		Expr* expr = parse_expression(tokens, idx);
		if (expr) {
			ASTNode* node = new VariableDeclaration("NDT", name, expr);
			parser_variables.push_back(name); // add variable to the list of variables
			AST.push_back(node);
			idx++;
		} else {
			report_error("Expression parsing failed", start_line, start_line_nb);
		}
	}
}

void parse_assignment_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses an assignment statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the assignment statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	string name=tokens[idx].value;
	idx++; // consume variable name
	if (tokens[idx].value == "--") {
		// handle decrement operator
		if (parser_variables.empty() || find(parser_variables.begin(), parser_variables.end(), name) == parser_variables.end()) {
			report_error("Variable '" + name + "' not declared.", start_line, start_line_nb);
			return;
		}
		ASTNode* node = new AssignStatement(new BinaryExpr(new Refrence(name), "-", new IntLiteral(1)), name);
		AST.push_back(node);
		idx+=2;
		return;
	} else if (tokens[idx].value == "++") {
		// handle increment operator
		if (parser_variables.empty() || find(parser_variables.begin(), parser_variables.end(), name) == parser_variables.end()) {
			report_error("Variable '" + name + "' not declared.", start_line, start_line_nb);
			return;
		}
		ASTNode* node = new AssignStatement(new BinaryExpr(new Refrence(name), "+", new IntLiteral(1)), name);
		AST.push_back(node);
		idx+=2;
		return;
	} else if (tokens[idx].value == "+=") {
		// handle add operator
		if (parser_variables.empty() || find(parser_variables.begin(), parser_variables.end(), name) == parser_variables.end()) {
			report_error("Variable '" + name + "' not declared.", start_line, start_line_nb);
			return;
		}
		idx++; // consume '+=' operator
		ASTNode* node = new AssignStatement(new BinaryExpr(new Refrence(name), "+", parse_expression(tokens, idx)), name);
		AST.push_back(node);
		idx++; // consume new line
		return;
	} else if (tokens[idx].value == "-=") {
		// handle subtract operator
		if (parser_variables.empty() || find(parser_variables.begin(), parser_variables.end(), name) == parser_variables.end()) {
			report_error("Variable '" + name + "' not declared.", start_line, start_line_nb);
			return;
		}
		idx++; // consume '-=' operator
		ASTNode* node = new AssignStatement(new BinaryExpr(new Refrence(name), "-", parse_expression(tokens, idx)), name);
		AST.push_back(node);
		idx++; // consume new line
		return;
	} else if (tokens[idx].value == "*=") {
		// handle multiply operator
		if (parser_variables.empty() || find(parser_variables.begin(), parser_variables.end(), name) == parser_variables.end()) {
			report_error("Variable '" + name + "' not declared.", start_line, start_line_nb);
			return;
		}
		idx++; // consume '*=' operator
		ASTNode* node = new AssignStatement(new BinaryExpr(new Refrence(name), "*", parse_expression(tokens, idx)), name);
		AST.push_back(node);
		idx++; // consume new line
		return;
	} else if (tokens[idx].value == "/=") {
		// handle divide operator
		if (parser_variables.empty() || find(parser_variables.begin(), parser_variables.end(), name) == parser_variables.end()) {
			report_error("Variable '" + name + "' not declared.", start_line, start_line_nb);
			return;
		}
		idx++; // consume '/=' operator
		ASTNode* node = new AssignStatement(new BinaryExpr(new Refrence(name), "/", parse_expression(tokens, idx)), name);
		AST.push_back(node);
		idx++; // consume new line
		return;
	}
	idx++; // consume '=' operator

	if (idx<tokens.size()) {
		Expr* expr = parse_expression(tokens, idx);
		ASTNode* node = new AssignStatement(expr, name);
		AST.push_back(node);
		idx++;
		return;
	} else {
		report_error("Expected identifier after variable name.", start_line, start_line_nb);
		return;
	}
}

void parse_fc_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses an assignment statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the assignment statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	string name=tokens[idx].value;
	idx++; // consume function name

	if (idx<tokens.size() && tokens[idx].type=="LPAREN") {
		idx++; // consume '('
		vector<Expr*> args;
		while (idx < tokens.size() && tokens[idx].type != "RPAREN") {
			Expr* arg = parse_expression(tokens, idx);
			if (arg) {
				args.push_back(arg);
			} else {
				report_error("Expected expression in function call arguments.", start_line, start_line_nb);
				return;
			}
			if (idx < tokens.size() && tokens[idx].type == "COMMA") {
				idx++; // consume ','
			}
		}
		ASTNode* node = new FunctionCall(name, args);
		AST.push_back(node);
		idx+=2;
		return;
	} else {
		report_error("Expected identifier after variable name.", start_line, start_line_nb);
		return;
	}
}

void parse_print_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a print statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the print statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++;

	if (idx<tokens.size()) {
		ASTNode* node = new PrintStatement(parse_expression(tokens, idx));
		AST.push_back(node);
		idx++;
		return;
	} else {
		report_error("Expected identifier after 'afiseaza'", start_line, start_line_nb);
		return;
	}
}

vector<ASTNode*> functionDefinitions;

void parse_fd_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a function definition statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the function definition statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++;

	if (idx<tokens.size() && tokens[idx].type=="ID") {
		string name=tokens[idx].value;
		vector<ASTNode*> args, block;
		idx++;
		if (tokens[idx].type != "LPAREN"){
			throw "Expected '(' after function name.";
		}
		idx++;
		while (idx<tokens.size()){
			parse_variable_declaration(tokens,idx,args);
			if (tokens[idx].value!="var") break;
		}
		block=parse_block(tokens,idx);
		ASTNode* node=new FunctionDefinition(name,args,block);
		AST.push_back(node);
		functionDefinitions.push_back(node);
		parser_user_defined_fn.push_back(name);
		return;
	} else {
		report_error("Expected identifier after 'functie'", start_line, start_line_nb);
		return;
	}
}


void parse_input_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a input statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the input statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++;

	if (idx<tokens.size() && tokens[idx].type=="ID") {
		ASTNode* node = new InputStatement(tokens[idx].value);
		AST.push_back(node);
		idx+=2;
		return;
	} else {
		report_error("Expected identifier after 'citeste'", start_line, start_line_nb);
		return;
	}
}

void parse_for_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a for statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the for statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++; // consume "pentru"

	if (tokens[idx].type != "LPAREN") {
		report_error("Expected '(' after 'pentru'", start_line, start_line_nb);
		return;
	}

	idx++; // consume '('

	vector<ASTNode*> init_block; // initialization block
	Expr* condition = nullptr; // loop condition

	if (tokens[idx].type == "KEYWORD" && tokens[idx].value == "var") {
		parse_variable_declaration(tokens, idx, init_block); // parse variable declaration
	} else if (tokens[idx].type == "ID") {
		parse_assignment_statement(tokens, idx, init_block); // parse assignment statement
	} else {
		report_error("Expected variable declaration or assignment after 'pentru ('", start_line, start_line_nb);
		return;
	}

	condition = parse_expression(tokens, idx); // parse loop condition
	
	if (tokens[idx].value == ";"){
		idx++; // consume ';'
	} else {
		report_error("Expected ';' after loop condition", start_line, start_line_nb);
		return;
	}

	if (tokens[idx].type == "ID") {
		parse_assignment_statement(tokens, idx, init_block); // parse assignment statement
	} else {
		report_error("Expected variable declaration or assignment after 'pentru ('", start_line, start_line_nb);
		return;
	}

	vector<ASTNode*> block = parse_block(tokens, idx); // main for block
	if (block.empty()) {
		report_error("Expected block after 'pentru (...)'", start_line, start_line_nb);
		return;
	}

	ASTNode* node = new ForStatement(init_block[0], condition, block, init_block[1]);
	AST.push_back(node);
	return;
}

void parse_while_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a while statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the while statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++; // cat keyword

	if (tokens[idx].value == "timp") { // support for "timp" keyword
		idx++; // consume "timp"
	}

	if (idx<tokens.size() && tokens[idx].type=="LPAREN") {
		Expr* condition = parse_expression(tokens, idx);
		if (tokens[idx].value=="executa"){ // support for "executa" keyword
			idx++; // consume "executa"
		}
		vector<ASTNode*> block = parse_block(tokens, idx); // main while block
		ASTNode* node = new WhileStatement(condition, block);
		AST.push_back(node);
		return;
	} else {
		report_error("Expected '(' after 'cat'/'cat timp'", start_line, start_line_nb);
		return;
	}
}

void parse_do_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses a do while/until statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the do while/until statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++; // repeta keyword

	vector<ASTNode*> block; // main do while block
	block = parse_block(tokens, idx); // parse the block
	if (block.empty()) {
		report_error("Expected block after 'repeta'", start_line, start_line_nb);
		return;
	}

	if (tokens[idx].value == "cat") { // support for "cat" keyword
		idx++; // consume "cat"
		if (tokens[idx].value == "timp") { // support for "timp" keyword
			idx++; // consume "timp"
		}
		Expr* condition = parse_expression(tokens, idx);
		ASTNode* node = new DoWhileStatement(condition, block);
		AST.push_back(node);
		return;
	} else if (tokens[idx].value == "pana") { // support for "pana" keyword
		idx++; // consume "pana"
		if (tokens[idx].value == "cand") { // support for "cand" keyword
			idx++; // consume "cand"
		}
		Expr* condition = parse_expression(tokens, idx);
		ASTNode* node = new DoUntilStatement(condition, block);
		AST.push_back(node);
		return;
	} else {
		report_error("Expected 'cat' or 'pana' after 'repeta'", start_line, start_line_nb);
		return;
	}
}

void parse_if_statement(const vector<Token>& tokens, int& idx, vector<ASTNode*>& AST) {
	/**
 	* @brief Parses an if statement line.
 	* @param tokens The tokens to parse.
 	* @param idx Current token index.
 	* @return Adds the if statement to the AST.
	 */

	int start_line_nb=tokens[idx].line_nb;
	string start_line=tokens[idx].line;
	idx++;

	if (idx<tokens.size() && tokens[idx].type=="LPAREN") {
		Expr* condition = parse_expression(tokens, idx);
		if (tokens[idx].value=="atunci"){ // support for "atunci" keyword
			idx++; // consume "atunci"
		}

		vector<ASTNode*> block = parse_block(tokens, idx); // main if block
		vector<ASTNode*> else_block; // else block
		vector<pair<Expr*, vector<ASTNode*>>> elseif_branches; // else if branches

		while (idx < tokens.size() && tokens[idx].type == "KEYWORD" && tokens[idx].value == "altfel") {
			idx++; // consume "altfel"
			if (idx < tokens.size() && tokens[idx].value == "daca") {
				idx++; // consume "daca"
				Expr* elseif_condition = parse_expression(tokens, idx);
				if (tokens[idx].value == "atunci") { // support for "atunci" keyword
					idx++; // consume "atunci"
				}
				vector<ASTNode*> elseif_block = parse_block(tokens, idx);
				elseif_branches.push_back({elseif_condition, elseif_block});
			} else {
				if (tokens[idx].type == "LBRACE") {
					else_block = parse_block(tokens, idx); // else block
				} else if (tokens[idx].value == "atunci") {
					idx++; // consume "atunci"
					if (tokens[idx].type == "LBRACE") {
						else_block = parse_block(tokens, idx); // else block
					} else {
						report_error("Expected '{' after 'altfel atunci'", start_line, start_line_nb);
						return;
					}
				} else {
					report_error("Expected '{' after 'altfel'", start_line, start_line_nb);
					return;
				}
			}
		}
		ASTNode* node = new IfStatement(condition, block, elseif_branches, else_block);
		AST.push_back(node);
		return;
	}
}

// Start of the parser function

vector<ASTNode*> parse(vector<pair<string, string>> tokens, vector<int> tokens_per_line) {
	/**
 	* @brief Parses the tokens and creates the AST.
 	* @param tokens The tokens to parse.
 	* @return The AST.
 	* @note This function is the main entry point for the parser. It takes the tokens generated by the lexer and creates the AST.
	 */

	TokenStream stream;
	stream.raw_tokens = tokens; //the only place where we use the raw tokens
	stream.init(tokens_per_line);

	int idx = 0; // token counter

	while (idx<stream.tokens.size()){
		string& type=stream.tokens[idx].type;
		string& value=stream.tokens[idx].value;
		if (type == "KEYWORD" && value == "var") {
			parse_variable_declaration(stream.tokens, idx, AST); // parse variable declaration
		/*} else if (type == "KEYWORD" && value == "afiseaza") {
			parse_print_statement(stream.tokens, idx, AST); // parse print statement
		} else if (type == "KEYWORD" && value == "citeste") {
			parse_input_statement(stream.tokens, idx, AST); // parse print statement */
		} else if (type == "ID" && find(parser_variables.begin(),parser_variables.end(),value)!= parser_variables.end()) {
			parse_assignment_statement(stream.tokens, idx, AST); // parse assignment statement
		} else if (type == "ID" && (stdlib.find(value) != stdlib.end()||find(parser_user_defined_fn.begin(),parser_user_defined_fn.end(),value)!=parser_user_defined_fn.end())) {
			parse_fc_statement(stream.tokens, idx, AST); // parse FunctionCall statement
		} else if (type == "KEYWORD" && value == "functie") {
			parse_fd_statement(stream.tokens,idx,AST); // parse FunctionDeclaration statement
		} else if (type == "KEYWORD" && value == "daca") {
			parse_if_statement(stream.tokens, idx, AST); // parse if statement
		} else if (type == "KEYWORD" && value == "cat") {
			parse_while_statement(stream.tokens, idx, AST); // parse while statement
		} else if (type == "KEYWORD" && value == "pentru") {
			parse_for_statement(stream.tokens, idx, AST); // parse for statement
		} else if (type == "KEYWORD" && value == "repeta") {
			parse_do_statement(stream.tokens,idx,AST); // parse do statement
		} else {
			report_error("Unexpected token: " + value, stream.tokens[idx].line, stream.tokens[idx].line_nb);
			idx++; // skip the unexpected token
		}
	}

	return AST;
}

vector<ASTNode*> parse_block(vector<Token> tokens, int& idx) {
	/**
 	* @brief Parses the tokens and creates the AST for a block of code.
 	* @param idx The current index in the tokens vector.
 	* @param tokens The tokens to parse.
 	* @return The AST of the block.
	 */

	if (idx >= tokens.size() || tokens[idx].type != "LBRACE") {
		report_error("Expected '{' to start a block", tokens[idx].line, tokens[idx].line_nb);
		return {};
	}
	idx++; // consume '{'
	int ct = 1; // brace counter

	vector<ASTNode*> ASTb; // AST for the block

	while (idx<tokens.size()){
		string& type=tokens[idx].type;
		string& value=tokens[idx].value;
		if (type == "RBRACE") { 
			ct--;
			if (ct==0) {
				idx++; // consume '}'
				return ASTb; // end of block
			}
			idx++; // consume '}'
		}
		if (type == "LBRACE") {
			ct++;
		}
		if (type == "KEYWORD" && value == "var") {
			parse_variable_declaration(tokens, idx, ASTb); // parse variable declaration
		/*} else if (type == "KEYWORD" && value == "afiseaza") {
			parse_print_statement(tokens, idx, ASTb); // parse print statement
		} else if (type == "KEYWORD" && value == "citeste") {
			parse_input_statement(tokens, idx, ASTb); // parse input statement */
		} else if (find(parser_variables.begin(),parser_variables.end(),value)!= parser_variables.end()) {
			parse_assignment_statement(tokens, idx, ASTb); // parse print statement
		} else if (type == "ID" && (stdlib.find(value) != stdlib.end()||find(parser_user_defined_fn.begin(),parser_user_defined_fn.end(),value)!=parser_user_defined_fn.end())) {
			parse_fc_statement(tokens, idx, ASTb); // parse FC statement
		} else if (type == "KEYWORD" && value == "functie") {
			parse_fd_statement(tokens,idx,ASTb); // parse FunctionDeclaration statement

		} else if (type == "KEYWORD" && value == "daca") {
			parse_if_statement(tokens, idx, ASTb); // parse if statement
		} else if (type == "KEYWORD" && value == "cat") {
			parse_while_statement(tokens, idx, ASTb); // parse while statement
		} else if (type == "KEYWORD" && value == "pentru") {
			parse_for_statement(tokens, idx, ASTb); // parse for statement
		} else if (type == "KEYWORD" && value == "repeta") {
			parse_do_statement(tokens, idx, ASTb); // parse do statement
		} else {
			report_error("Unexpected token: " + value, tokens[idx].line, tokens[idx].line_nb);
			idx++; // skip the unexpected token
		}
	}

	return ASTb;
}
